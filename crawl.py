import pandas as pd
import requests
import time
from datetime import datetime, timedelta
from bs4 import BeautifulSoup


# =========================
# 1ï¸âƒ£ NBA ê³µì‹ CDNì—ì„œ ê²½ê¸° ë°ì´í„° ìˆ˜ì§‘ (ìœ ì¼í•œ ì‹¤ì‚¬ìš© ë£¨íŠ¸)
# =========================
def fetch_with_nba_cdn(days=180):
    print("ğŸŒ [CDN] NBA ê³µì‹ scoreboard JSON ìˆ˜ì§‘ ì‹œì‘")

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Accept": "application/json",
        "Referer": "https://www.nba.com/",
        "Origin": "https://www.nba.com"
    }

    # ğŸ”¥ í•µì‹¬: ì–´ì œê¹Œì§€ë§Œ ìˆ˜ì§‘ (UTC ê¸°ì¤€)
    end_date = datetime.utcnow().date() - timedelta(days=1)
    start_date = end_date - timedelta(days=days)

    games = []

    date = start_date
    while date <= end_date:
        date_str = date.strftime("%Y%m%d")
        url = f"https://cdn.nba.com/static/json/liveData/scoreboard/scoreboard_{date_str}.json"

        try:
            res = requests.get(url, headers=headers, timeout=10)
            if res.status_code != 200:
                date += timedelta(days=1)
                continue

            data = res.json()
            game_list = data.get("scoreboard", {}).get("games", [])

            if not game_list:
                date += timedelta(days=1)
                continue

            for g in game_list:
                matchup = f"{g['awayTeam']['teamTricode']} @ {g['homeTeam']['teamTricode']}"

                # í™ˆíŒ€
                games.append({
                    "GAME_ID": g["gameId"],
                    "GAME_DATE": date,
                    "TEAM_ID": g["homeTeam"]["teamId"],
                    "TEAM_ABBREVIATION": g["homeTeam"]["teamTricode"],
                    "MATCHUP": matchup,
                    "PTS": g["homeTeam"].get("score", 0),
                    "WL": None
                })

                # ì›ì •íŒ€
                games.append({
                    "GAME_ID": g["gameId"],
                    "GAME_DATE": date,
                    "TEAM_ID": g["awayTeam"]["teamId"],
                    "TEAM_ABBREVIATION": g["awayTeam"]["teamTricode"],
                    "MATCHUP": matchup,
                    "PTS": g["awayTeam"].get("score", 0),
                    "WL": None
                })

        except Exception as e:
            print(f"âš ï¸ CDN ìš”ì²­ ì˜¤ë¥˜ ({date}): {e}")

        date += timedelta(days=1)
        time.sleep(0.2)

    if not games:
        print("âŒ CDNì—ì„œ ê²½ê¸° ë°ì´í„° ì—†ìŒ (ì •ìƒ ì¢…ë£Œ)")
        return pd.DataFrame()

    df = pd.DataFrame(games)
    df["GAME_DATE"] = pd.to_datetime(df["GAME_DATE"])
    df = df.sort_values("GAME_DATE", ascending=False)

    print(f"âœ… CDN ê²½ê¸° ë°ì´í„° {len(df)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
    return df


# =========================
# 2ï¸âƒ£ CBS Sports ë¶€ìƒì ë‰´ìŠ¤
# =========================
def fetch_injury_news():
    print("ğŸš‘ [NEWS] CBS Sports ë¶€ìƒì ë‰´ìŠ¤ ìˆ˜ì§‘")

    url = "https://www.cbssports.com/nba/injuries/"
    headers = {"User-Agent": "Mozilla/5.0"}

    res = requests.get(url, headers=headers, timeout=15)
    soup = BeautifulSoup(res.text, "html.parser")

    news = []

    rows = soup.select("table tr")[1:]
    for row in rows:
        cols = row.find_all("td")
        if len(cols) >= 5:
            news.append({
                "TEAM": cols[1].text.strip(),
                "NEWS": f"{cols[4].text.strip()}: {cols[0].text.strip()} ({cols[3].text.strip()})"
            })

    if news:
        pd.DataFrame(news).to_csv("nba_news.csv", index=False, encoding="utf-8-sig")
        print(f"âœ… ë¶€ìƒì ë‰´ìŠ¤ {len(news)}ê±´ ì €ì¥")
    else:
        print("âš ï¸ ë¶€ìƒì ë‰´ìŠ¤ ì—†ìŒ")


# =========================
# 3ï¸âƒ£ MAIN PIPELINE
# =========================
def collect_real_data():
    print("ğŸš€ NBA ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ì‹œì‘")

    df = fetch_with_nba_cdn(days=180)

    if df.empty:
        print("âŒ ê²½ê¸° ë°ì´í„° ì—†ìŒ â†’ ì´ì „ ë°ì´í„° ìœ ì§€")
        return

    df.to_csv("nba_history_3years.csv", index=False, encoding="utf-8-sig")
    print(f"ğŸ“ nba_history_3years.csv ì €ì¥ ì™„ë£Œ ({len(df)}ê±´)")

    fetch_injury_news()


if __name__ == "__main__":
    collect_real_data()

